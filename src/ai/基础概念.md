# 基础概念

## 大语言模型 (Large Language Model, LLM)

### 1. 是什么

- **英文名称：** Large Language Model (LLM)
- **官方定义：** 大语言模型是一种基于深度学习的语言模型，它通过在海量文本数据上进行训练，学习语言的统计规律和语义信息，从而能够理解、生成和处理人类语言。这些模型通常拥有数十亿甚至数千亿的参数，使其能够捕捉到复杂的语言模式。
- **通俗理解：** 想象一个非常非常博学且能言善辩的“语言大师”。它读遍了互联网上几乎所有的文字，因此对各种知识、表达方式、写作风格都了如指掌。当你给它一个问题或一个任务时，它能像人一样理解你的意图，并用流畅、自然、有逻辑的语言给出回答或完成任务。它不是简单地查找信息，而是能够进行推理、总结、创作。

### 2. 为什么

- **为什么存在：** 随着计算能力的提升和海量数据的积累，研究人员发现通过增加模型规模（参数量）和训练数据量，语言模型的性能会发生质的飞跃，展现出涌现能力（Emergent Abilities），即小模型不具备的能力。这使得构建能够处理复杂语言任务的通用模型成为可能。
- **为什么选择（市场为什么选择这个方案/技术）：**
  - **通用性强：** 一个模型可以处理多种不同的自然语言处理任务，如问答、翻译、摘要、代码生成等，降低了开发成本。
  - **效果显著：** 在许多任务上达到了甚至超越了人类水平。
  - **交互自然：** 能够理解和生成自然语言，使得人机交互更加直观和高效。
  - **应用潜力巨大：** 在智能客服、内容创作、教育、医疗等领域有广泛的应用前景。
- **为什么重要：** LLM被认为是人工智能领域的一个里程碑，它极大地推动了自然语言处理技术的发展，并正在改变我们与计算机交互的方式。它为构建更智能、更通用的人工智能系统奠定了基础，是实现通用人工智能（AGI）的关键一步。

### 3. 怎么做

- **训练阶段：**
  - **数据收集与预处理：** 收集海量的文本数据（如书籍、文章、网页、代码等），并进行清洗、去重、格式化等处理。
  - **模型架构选择：** 通常采用Transformer架构，因为它在处理序列数据方面表现出色，并能有效利用并行计算。
  - **预训练：** 在大规模无标注文本数据上进行自监督学习，例如通过预测下一个词（Causal Language Modeling）或填充缺失的词（Masked Language Modeling）来学习语言的统计规律。
  - **计算资源：** 需要巨大的计算资源（如GPU集群）和时间来完成训练。
- **微调与应用阶段：**
  - **指令微调 (Instruction Tuning)：** 在少量高质量的指令-响应对数据上进行训练，使模型更好地理解和遵循人类指令。
  - **对齐 (Alignment)：** 通过人类反馈强化学习 (Reinforcement Learning from Human Feedback, RLHF) 等技术，使模型的输出更符合人类的价值观和偏好，减少有害、偏见或不准确的回答。
  - **部署与推理：** 将训练好的模型部署到服务器或云端，通过API或界面提供服务，接收用户输入并生成响应。
  - **应用开发：** 开发者基于LLM构建各种应用，如聊天机器人、智能写作助手、代码生成工具等。

### 4. 其他相关概念

- **Transformer：** LLM的核心架构，一种神经网络模型，通过自注意力机制（Self-Attention Mechanism）有效处理序列数据。
- **涌现能力 (Emergent Abilities)：** LLM在达到一定规模后，突然展现出的、在小模型中不具备的能力，如上下文学习、复杂推理等。
- **提示工程 (Prompt Engineering)：** 设计和优化输入给LLM的提示（Prompt），以引导模型生成期望的输出。
- **RAG (Retrieval-Augmented Generation)：** 检索增强生成，结合信息检索系统，让LLM在生成回答前先从外部知识库中检索相关信息，以提高回答的准确性和时效性。
- **多模态大模型 (Multimodal LLM)：** 能够处理和理解多种类型数据（如文本、图像、音频、视频）的LLM。

## Agent (AI Agent)

### 1. 是什么

- **英文名称：** AI Agent (Artificial Intelligence Agent)
- **官方定义：** 在人工智能领域，Agent（智能体）是一个能够感知环境、通过推理和决策来执行动作，并以实现特定目标为导向的实体。它通常具备感知（Perception）、思考（Reasoning/Planning）、行动（Action）的能力，并能与环境进行交互。
- **通俗理解：** 想象一个拥有自主行动能力的“智能助手”。它不仅仅是简单地回答问题，而是能够理解你的目标，然后自主地规划步骤、调用工具、执行任务，并根据环境反馈进行调整，直到目标达成。它就像一个拥有“大脑”和“手脚”的机器人，能够独立完成复杂的工作。

### 2. 为什么

- **为什么存在：** 随着大语言模型（LLM）能力的提升，人们发现LLM虽然强大，但它们本身是“无状态”且“无行动力”的。它们能生成文本，但不能直接感知外部世界、执行复杂任务或长期规划。Agent的概念应运而生，旨在将LLM的“智能”与“行动”结合起来，使其能够自主地完成更复杂的、需要多步骤和外部交互的任务。
- **为什么选择（市场为什么选择这个方案/技术）：**
  - **弥补LLM的局限性：** 赋予LLM感知、规划和执行的能力，使其从一个“语言生成器”转变为一个“任务执行器”。
  - **自动化复杂任务：** 能够自主地完成需要多步骤、多工具协作的复杂任务，极大地提高了效率。
  - **提升用户体验：** 用户只需提出高层目标，Agent就能自主完成细节，降低了使用门槛。
  - **实现更高级别的AI应用：** 是构建更通用、更自主的AI系统（如自动化研究员、智能编程助手、虚拟个人助理）的关键。
- **为什么重要：** Agent是实现通用人工智能（AGI）的重要路径之一。它将LLM的强大推理和语言能力与实际行动相结合，使得AI能够走出“对话框”，真正进入现实世界，自主地解决问题和创造价值。它代表了AI从“工具”向“伙伴”演进的重要方向。

### 3. 怎么做

- **核心组件：**
  - **感知模块 (Perception)：** 接收来自环境的信息（如用户输入、文件内容、网页信息、API返回结果等）。
  - **规划/推理模块 (Planning/Reasoning)：** 通常由LLM充当，根据感知到的信息和目标，进行思考、分解任务、制定执行计划、选择合适的工具。
  - **记忆模块 (Memory)：** 存储短期（如当前对话上下文）和长期（如学习到的知识、历史经验）信息，以便Agent在执行任务时进行参考和学习。
  - **工具使用模块 (Tool Usage)：** 能够调用外部工具（如代码解释器、网页浏览器、API接口、文件操作工具等）来执行特定动作，获取信息或改变环境。
  - **行动模块 (Action)：** 根据规划执行具体的动作，包括调用工具、生成文本、与用户交互等。
- **工作流程（ReAct模式为例）：**
  1. **观察 (Observe)：** Agent感知环境，接收用户指令或外部事件。
  2. **思考 (Think/Thought)：** LLM根据观察到的信息和目标，进行推理，生成下一步的思考过程（Thought）。
  3. **行动 (Act)：** LLM根据思考结果，决定执行哪个工具（Tool）以及工具的参数，或者直接生成响应。
  4. **循环：** Agent执行行动后，再次观察环境（工具的执行结果），然后进入下一个思考-行动循环，直到目标达成或遇到无法解决的问题。
  5. 最终答案（Final Answer）：Agent根据最终的行动结果，生成用户可理解的回答或执行结果。

### 4. 其他相关概念

- **ReAct (Reasoning and Acting)：** 一种流行的Agent设计模式，结合了推理（Reasoning）和行动（Acting），使LLM能够通过内部思考和外部工具使用来解决复杂任务。
- **工具调用 (Tool Calling)：** Agent能够识别何时以及如何调用外部工具来扩展其能力，例如搜索网页、执行代码、访问数据库等。
- **多Agent系统 (Multi-Agent Systems)：** 多个Agent协同工作，共同完成一个复杂任务的系统。每个Agent可能负责不同的子任务或拥有不同的专长。
- **自主性 (Autonomy)：** Agent在多大程度上能够独立地感知、思考、规划和执行任务，而无需人类的持续干预。
- **Agent框架：** 帮助开发者构建和部署Agent的软件库和平台，如LangChain, AutoGen等。

## MCP (模型上下文协议 / Model Context Protocol)

### 1. 是什么

英文名称： Model Context Protocol (MCP)
MCP 是一个开放协议，它规范了应用程序向 LLM 提供上下文的方式。
MCP 就像 AI 应用程序的 USB-C 端口一样。
正如 USB-C 提供了一种标准化的方式将您的设备连接到各种外围设备和配件一样，
MCP 也提供了一种标准化的方式将 AI 模型连接到不同的数据源和工具。

### 为什么

MCP 可帮助您在 LLM 之上构建代理和复杂的工作流。LLM 通常需要与数据和工具集成，而 MCP 可提供以下功能：

- 越来越多的预建集成可供您的 LLM 直接插入
- 在 LLM 提供商和供应商之间切换的灵活性
- 保护基础架构内数据的最佳实践

### 总体架构

- MCP Hosts(MCP 主机)：像 Claude Desktop、IDE 或 AI Tools 这样的程序，需要通过 MCP 访问数据
- MCP Clients(MCP 客户端)：与服务器保持 1:1 连接的协议客户端
- MCP Servers(MCP 服务器)：轻量级程序，每个程序都通过标准化模型上下文协议公开特定功能
- Local Data Sources(本地数据源)：MCP 服务器可以安全访问的您计算机上的文件、数据库和服务
- Remote Services(远程服务)：MCP 服务器可以通过互联网（例如通过 API）连接到的外部系统

### 3. 怎么做

使用 `@modelcontextprotocol/typescript-sdk`
